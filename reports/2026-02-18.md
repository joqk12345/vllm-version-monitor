# vLLM 每日报告

## 日期：2026-02-18

## 版本信息

### PyPI 版本：0.15.1

### GitHub 发布版本：v0.15.1

## 版本对比

从 0.0.0 更新到 v0.15.1

## 每日提交

- 7743152957236f21fc36f0402f9678159976ccc5 - [Attention] Refactor `check_and_update_config` (#33600)

Signed-off-by: Matthew Bonanni <mbonanni@redhat.com> (2026-02-18 01:06:54)
- ab33d2a629be6eca2dd946b1628af4d23d39c547 - [Feature] Decode Context Parallel support for GPU model runner v2 (#34179)

Signed-off-by: yewentao256 <zhyanwentao@126.com> (2026-02-18 00:27:15)

## 热门 Issues 和 PRs

- #20859: [Feature] limit thinking tokens (hard limit) (51 条评论)
- #26278: [1/N] Elastic EP Milestone 2 (31 条评论)
- #29184: [Core] NGram GPU Implementation compatible with Async Scheduler (26 条评论)
- #29117: [torch.compile] refactor config hashing to compile_factors and unify factor collection (44 条评论)
- #32420: [Frontend] Enable drain shutdown mode for non-DP deployments (27 条评论)

## 功能更新

待实现

## Bug 修复

待实现

## 性能改进

待实现

---

*Generated by vLLM Version Monitor Skill*
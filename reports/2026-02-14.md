# vLLM 每日报告

## 日期：2026-02-14

## 版本信息

### PyPI 版本：0.15.1

### GitHub 发布版本：v0.15.1

## 版本对比

从 0.0.0 更新到 v0.15.1

## 每日提交

- d1ea65d0a1c606ae041b73fd45ccd33980ca08e7 - [new model] add COLQwen3 code & Inference (#34398)

Signed-off-by: craftsangjae <craftsangjae@gmail.com>
Signed-off-by: katacoder <craftsangjae@gmail.com> (2026-02-14 04:15:19)
- de42abb366032519bca073e057331ead6270e09f - [CI] Heavy refactoring of Voxtral multimodal audio model tests (#34294)

Signed-off-by: Andreas Karatzas <akaratza@amd.com> (2026-02-14 04:04:29)
- 60ca7981bce1bd6e2155df1a58bc9f916f7c4093 - Add explicit validation error for tool calls. (#34438)

Signed-off-by: juliendenize <julien.denize@mistral.ai> (2026-02-14 04:04:01)
- 0ef5b9147bb1f37c9a90ab2a3ee2a85cf9e84e30 - fix: use `__annotations__` instead of `get_type_hints()` for dynamic `kwargs` detection (#34527)

Signed-off-by: Christian S. Perone <christian.perone@gmail.com>
Signed-off-by: Christian S. Perone <perone@users.noreply.github.com>
Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com> (2026-02-14 04:03:37)
- ed242652d7f9cb4222e8840311b5229295b5d266 - [bug] Make sure get_modality_with_max_tokens is deterministic (#34533)

Signed-off-by: Shiyan Deng <dsy842974287@meta.com> (2026-02-14 04:02:59)
- b37b679770aade27f33d20c93bf467c6a7fba65d - [Feature][Perf] Support Selective CPU Weight Offloading (#34535)

Signed-off-by: wzhao18 <wzhao18.sz@gmail.com> (2026-02-14 04:02:24)
- a0638d052db74ba28eada4768b9bbf98720b44a4 - [Bugfix] Fix ROCm UVA CPU weight offloading broken by #32993 (#34543)

Signed-off-by: Andreas Karatzas <akaratza@amd.com> (2026-02-14 04:01:42)

## 热门 Issues 和 PRs

- #20859: [Feature] limit thinking tokens (hard limit) (51 条评论)
- #26278: [1/N] Elastic EP Milestone 2 (31 条评论)
- #29184: [Core] NGram GPU Implementation compatible with Async Scheduler (25 条评论)
- #14452: [Doc]: Steps to run vLLM on your RTX5080 or 5090! (135 条评论)
- #29117: [torch.compile] refactor config hashing to compile_factors and unify factor collection (44 条评论)

## 功能更新

待实现

## Bug 修复

待实现

## 性能改进

待实现

---

*Generated by vLLM Version Monitor Skill*
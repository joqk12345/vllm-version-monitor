# vLLM 每日报告

## 日期：2026-02-28

## 版本信息

### PyPI 版本：0.16.0

### GitHub 发布版本：v0.16.0

## 版本对比

从 0.0.0 更新到 v0.16.0

## 每日提交

- 405f28d38df2ea4f320635c6e87e206b3ccbea2f - [Misc] Clean up ResponsesRequest model validators (#35531)

Signed-off-by: umut-polat <52835619+umut-polat@users.noreply.github.com> (2026-02-28 01:19:21)
- 5323672bc2b448e94ba027b16d99c93aba9c72a4 - [misc] cleanup one level of error stack when nixl fails to initialize (#35517)

Signed-off-by: youkaichao <youkaichao@gmail.com> (2026-02-28 00:42:37)
- a201ad72d87eaaa1fe20e2f42378be4ddbc867f4 - [Refactor][Kernel] Add global helper to deduplicate vectorized memory ops (#35105)

Signed-off-by: LopezCastroRoberto <rocastro@redhat.com>
Signed-off-by: LopezCastroRoberto <roberto.lopez.castro@udc.es>
Signed-off-by: Roberto L. Castro <38211239+LopezCastroRoberto@users.noreply.github.com> (2026-02-28 00:28:17)

## 热门 Issues 和 PRs

- #20859: [Feature] limit thinking tokens (hard limit) (68 条评论)
- #29184: [Core] NGram GPU Implementation compatible with Async Scheduler (27 条评论)
- #29117: [torch.compile] refactor config hashing to compile_factors and unify factor collection (44 条评论)
- #20802: [Model] Add support for Jina Embeddings   V4 (16 条评论)
- #31941: LoRA Per Request Loading Pipelining Support (6 条评论)

## 功能更新

待实现

## Bug 修复

待实现

## 性能改进

待实现

---

*Generated by vLLM Version Monitor Skill*